<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Oversampling Methods on Porto Seguro Dataset</title>
    
    <!-- Include Highlight.js CSS and JavaScript for syntax highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>
<body>
    <h1>Patrick Church</h1>
    <p>Date: November 11, 2024</p>

    <h2>Introduction</h2>
    <p>
        In this assignment, I will explore and compare different oversampling methods on the widely-used Porto Seguro Insurance dataset to address class imbalance. 
        I will demonstrate the use of several techniques, including SMOTE, ADASYN, FastKDE, and Normalizing Flows, to generate synthetic samples for the minority 
        class. Each method takes a unique approach to balancing the dataset, from interpolative sampling to density estimation and generative modeling. 
        By applying these methods, I aim to improve the model's ability to accurately identify minority class instances and provide a comparative analysis 
        of the effectiveness of each approach.
    </p>

    <h2>Class Distribution Visualization</h2>
    <h3>Code Snippet</h3>
    <pre><code class="language-python">
# Python code used to generate the bar plot
count = train['target'].value_counts()
count_zeros = count[0]
count_ones = count[1]
count.plot(kind='bar', title='Count of Target Variable')
    </code></pre>

    <h3>Description</h3>
    <p>
        The code snippet above counts the occurrences of each class in the target variable of the Porto Seguro dataset. 
        Using the <code>value_counts()</code> function, it calculates the number of samples for each class: class 0 (majority) 
        and class 1 (minority). This information is then plotted as a bar chart, showing the distribution of the two classes.
    </p>

    <h3>Interpretation of the Plot</h3>
    <p>
        The bar chart below visualizes the class imbalance in the dataset. The majority class (class 0) has a significantly higher count 
        than the minority class (class 1), which highlights the need for oversampling techniques. Oversampling generates synthetic 
        samples for the minority class, helping balance the dataset and allowing the model to better learn the characteristics of the minority class.
    </p>

    
    <img src="Images/count_of_target_variable (1).png" alt="Count of Target Variable" width="600">


    
    <h2>Sampling a 20% Subset of the Data</h2>

    <p>
        Due to the large size of the Porto Seguro dataset, processing the entire dataset can be computationally expensive and time-consuming. 
        To address this, I used a 20% stratified sampling approach, which helps reduce the dataset size while preserving the distribution of 
        the target variable. This ensures that the sample contains a representative proportion of each class.
    </p>

    <p>
        In the code, I first dropped the <code>target</code> and <code>id</code> columns from the original data and applied Min-Max scaling to normalize the features. 
        Then, I combined the scaled features and the target variable into a single DataFrame. Using the <code>groupby</code> function, I sampled 20% of the data 
        from each class. This stratified sampling helps maintain the original class balance in the subset, making it suitable for subsequent analysis and modeling.
    </p>

    
    <h3>Code Snippet</h3>
    <pre><code class="language-python">
# Python code to take a 20% sample from the dataset
X = train.drop(columns=['target', 'id'])
y = train['target']
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
sample_fraction = 0.2

data = pd.concat([pd.DataFrame(X_scaled), pd.Series(y, name="target")], axis=1)
data_sampled = data.groupby("target").sample(frac=sample_fraction, random_state=42)

X_sampled = data_sampled.drop(columns="target")
y_sampled = data_sampled["target"]
    </code></pre>

<h2>Classifier Performance on Imbalanced Data Without Oversampling</h2>
    <p>
        This section demonstrates the performance of a straightforward classifier on the highly imbalanced Porto Seguro dataset, 
        without using any oversampling techniques. In this setup, the classifier is exposed to a dataset dominated by class 0 
        instances, with very few examples of class 1. As a result, the classifier achieves a high accuracy by predicting the 
        majority class (class 0) for nearly every test sample. However, this accuracy is misleading, as it does not reflect 
        the modelâ€™s ability to identify minority class instances accurately. This scenario highlights the limitations of 
        accuracy as a metric when dealing with highly imbalanced data.
    </p>

    <h3>Code Snippet</h3>
    <pre><code class="language-python">
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)

# Initializing and training the classifier
classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform')
classifier.fit(X_train, y_train)

# Making predictions
y_pred = classifier.predict(X_test)

# Calculating accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Generating and displaying the confusion matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
    </code></pre>

    <h3>Results</h3>
    <p>The classifier achieves a high accuracy of <strong>96.31%</strong>, largely due to predicting the majority class (0) for most samples. Below are the detailed metrics:</p>
    
    <pre><code class="language-text">
              precision    recall  f1-score   support

           0       0.96      1.00      0.98     22941
           1       0.19      0.00      0.01       868

    accuracy                           0.96     23809
   macro avg       0.58      0.50      0.49     23809
weighted avg       0.94      0.96      0.95     23809
    </code></pre>


    <h3>Confusion Matrix</h3>
    <p>This confusion matrix shows that the classifier predicts the majority class (0) almost exclusively, resulting in very few correct predictions for the minority class (1).</p>
    <img src="Images/confusion_matrix (1).png" alt="Confusion Matrix" width="500">

</body>
</html>
