<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Oversampling Methods on Porto Seguro Dataset</title>
    
    <!-- Include Highlight.js CSS and JavaScript for syntax highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>
<body>
    <h1>Patrick Church</h1>
    <p>Date: November 11, 2024</p>

    <h2>Introduction</h2>
    <p>
        In this assignment, I will explore and compare different oversampling methods on the widely-used Porto Seguro Insurance dataset to address class imbalance. 
        I will demonstrate the use of several techniques, including SMOTE, ADASYN, FastKDE, and Normalizing Flows, to generate synthetic samples for the minority 
        class. Each method takes a unique approach to balancing the dataset, from interpolative sampling to density estimation and generative modeling. 
        By applying these methods, I aim to improve the model's ability to accurately identify minority class instances and provide a comparative analysis 
        of the effectiveness of each approach.
    </p>

    <h2>Class Distribution Visualization</h2>
    <h3>Code Snippet</h3>
    <pre><code class="language-python">
# Python code used to generate the bar plot
count = train['target'].value_counts()
count_zeros = count[0]
count_ones = count[1]
count.plot(kind='bar', title='Count of Target Variable')
    </code></pre>

    <h3>Description</h3>
    <p>
        The code snippet above counts the occurrences of each class in the target variable of the Porto Seguro dataset. 
        Using the <code>value_counts()</code> function, it calculates the number of samples for each class: class 0 (majority) 
        and class 1 (minority). This information is then plotted as a bar chart, showing the distribution of the two classes.
    </p>

    <h3>Interpretation of the Plot</h3>
    <p>
        The bar chart below visualizes the class imbalance in the dataset. The majority class (class 0) has a significantly higher count 
        than the minority class (class 1), which highlights the need for oversampling techniques. Oversampling generates synthetic 
        samples for the minority class, helping balance the dataset and allowing the model to better learn the characteristics of the minority class.
    </p>

    
    <img src="Images/count_of_target_variable (1).png" alt="Count of Target Variable" width="600">


    
    <h2>Sampling a 20% Subset of the Data</h2>

    <p>
        Due to the large size of the Porto Seguro dataset, processing the entire dataset can be computationally expensive and time-consuming. 
        To address this, I used a 20% stratified sampling approach, which helps reduce the dataset size while preserving the distribution of 
        the target variable. This ensures that the sample contains a representative proportion of each class.
    </p>

    <p>
        In the code, I first dropped the <code>target</code> and <code>id</code> columns from the original data and applied Min-Max scaling to normalize the features. 
        Then, I combined the scaled features and the target variable into a single DataFrame. Using the <code>groupby</code> function, I sampled 20% of the data 
        from each class. This stratified sampling helps maintain the original class balance in the subset, making it suitable for subsequent analysis and modeling.
    </p>

    
    <h3>Code Snippet</h3>
    <pre><code class="language-python">
# Python code to take a 20% sample from the dataset
X = train.drop(columns=['target', 'id'])
y = train['target']
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
sample_fraction = 0.2

data = pd.concat([pd.DataFrame(X_scaled), pd.Series(y, name="target")], axis=1)
data_sampled = data.groupby("target").sample(frac=sample_fraction, random_state=42)

X_sampled = data_sampled.drop(columns="target")
y_sampled = data_sampled["target"]
    </code></pre>

<h2>Classifier Performance on Imbalanced Data Without Oversampling</h2>
    <p>
        This section demonstrates the performance of a straightforward classifier on the highly imbalanced Porto Seguro dataset, 
        without using any oversampling techniques. In this setup, the classifier is exposed to a dataset dominated by class 0 
        instances, with very few examples of class 1. As a result, the classifier achieves a high accuracy by predicting the 
        majority class (class 0) for nearly every test sample. However, this accuracy is misleading, as it does not reflect 
        the model’s ability to identify minority class instances accurately. This scenario highlights the limitations of 
        accuracy as a metric when dealing with highly imbalanced data.
    </p>

    <h3>Code Snippet</h3>
    <pre><code class="language-python">
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)

# Initializing and training the classifier
classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform')
classifier.fit(X_train, y_train)

# Making predictions
y_pred = classifier.predict(X_test)

# Calculating accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Generating and displaying the confusion matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
    </code></pre>

    <h3>Results</h3>
    <p>The classifier achieves a high accuracy of <strong>96.31%</strong>, largely due to predicting the majority class (0) for most samples. Below are the detailed metrics:</p>
    
    <pre><code class="language-text">
              precision    recall  f1-score   support

           0       0.96      1.00      0.98     22941
           1       0.19      0.00      0.01       868

    accuracy                           0.96     23809
   macro avg       0.58      0.50      0.49     23809
weighted avg       0.94      0.96      0.95     23809
    </code></pre>


    <h3>Confusion Matrix</h3>
    <p>This confusion matrix shows that the classifier predicts the majority class (0) almost exclusively, resulting in very few correct predictions for the minority class (1).</p>
    <img src="Images/confusion_matrix (1).png" alt="Confusion Matrix" width="500">

    <h2>Applying SMOTE to Address Class Imbalance</h2>
    <p>
        SMOTE (Synthetic Minority Over-sampling Technique) is an oversampling method commonly used to balance imbalanced datasets. 
        SMOTE generates synthetic samples for the minority class by interpolating between existing samples. Instead of simply duplicating 
        minority class samples, SMOTE selects two or more similar instances within the minority class and creates synthetic points along 
        the line segments connecting them. This technique helps improve the model’s ability to learn the characteristics of the minority 
        class without simply memorizing duplicates.
    </p>

    <h3>Code Snippet</h3>
    <pre><code class="language-python">
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled)

# Applying SMOTE
smote = SMOTE(random_state=42)
X_smote, y_smote = smote.fit_resample(X_train, y_train)

# Training the classifier
smote_classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform')
smote_classifier.fit(X_smote, y_smote)

# Making predictions
smote_y_pred = smote_classifier.predict(X_test)

# Calculating accuracy and displaying classification report
smote_accuracy = accuracy_score(y_test, smote_y_pred)
print(f"SMOTE Accuracy: {smote_accuracy * 100:.2f}%")
print(classification_report(y_test, smote_y_pred))

# Generating and displaying the confusion matrix
cm_smote = confusion_matrix(y_test, smote_y_pred)
sns.heatmap(cm_smote, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
    </code></pre>

    <h3>Results</h3>
    <p>The accuracy achieved with SMOTE is <strong>68.61%</strong>. While accuracy is lower than the classifier without oversampling, the model performs better on the minority class due to the balanced dataset. Here are the detailed metrics:</p>

    <pre><code class="language-text">
              precision    recall  f1-score   support

           0       0.97      0.70      0.81     22941
           1       0.04      0.34      0.07       868

    accuracy                           0.69     23809
   macro avg       0.50      0.52      0.44     23809
weighted avg       0.93      0.69      0.78     23809
    </code></pre>

    <!-- Confusion Matrix Image -->
    <h3>Confusion Matrix</h3>
    <p>The confusion matrix below illustrates how the SMOTE-based classifier performs on the test set, showing a slight improvement in identifying minority class instances:</p>
    <img src="Images/confusion_matrix (2).png" alt="SMOTE Confusion Matrix" width="500">

    <h2>Applying ADASYN to Address Class Imbalance</h2>
    <p>
        ADASYN (Adaptive Synthetic Sampling) is an oversampling technique that generates synthetic samples for the minority class based 
        on the density of the samples. ADASYN focuses more on the minority samples that are harder to classify, generating synthetic samples 
        around these challenging points. This approach helps in reducing the bias introduced by the class imbalance, improving the model's 
        ability to correctly classify instances of the minority class.
    </p>

    <h3>Code Snippet</h3>
    <pre><code class="language-python">
from imblearn.over_sampling import ADASYN
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Splitting the data
X_train, X_test, y_train, y_test = train_test_split(X_sampled, y_sampled, test_size=0.3, random_state=42, stratify=y_sampled)

# Applying ADASYN
adasyn = ADASYN()
X_ada, y_ada = adasyn.fit_resample(X_train, y_train)

# Training the classifier
ada_classifier = KNeighborsClassifier(n_neighbors=5, weights='uniform')
ada_classifier.fit(X_ada, y_ada)

# Making predictions
ada_y_pred = ada_classifier.predict(X_test)

# Calculating accuracy and displaying classification report
ada_accuracy = accuracy_score(y_test, ada_y_pred)
print(f"ADASYN Accuracy: {ada_accuracy * 100:.2f}%")
print(classification_report(y_test, ada_y_pred))

# Generating and displaying the confusion matrix
cm_ada = confusion_matrix(y_test, ada_y_pred)
sns.heatmap(cm_ada, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
    </code></pre>

    <h3>Results</h3>
    <p>The accuracy achieved with ADASYN is <strong>68.80%</strong>. This technique improves the model’s recall for the minority class by generating synthetic samples for challenging cases in the minority class. Here are the detailed metrics:</p>

    <pre><code class="language-text">
              precision    recall  f1-score   support

           0       0.97      0.70      0.81     34411
           1       0.04      0.35      0.08      1302

    accuracy                           0.69     35713
   macro avg       0.50      0.52      0.44     35713
weighted avg       0.93      0.69      0.79     35713
    </code></pre>

  
    <h3>Confusion Matrix</h3>
    <p>The confusion matrix below illustrates how the ADASYN-based classifier performs on the test set, showing an improvement in identifying minority class instances:</p>
    <img src="Images/confusion_matrix (3).png" alt="ADASYN Confusion Matrix" width="500">

<h2>Applying FastKDE to Address Class Imbalance with Synthetic Data</h2>
    <p>
        FastKDE (Fast Kernel Density Estimation) is a technique used for estimating the probability density function of a dataset. In this 
        implementation, we leverage FastKDE to generate synthetic minority samples (referred to as “fakes”) for the minority class. Using 
        FastKDE allows us to estimate regions with a higher density of minority samples and then generate synthetic samples in those regions. 
        This approach aims to create a balanced dataset that enables the classifier to perform better on the minority class.
    </p>

    <h3>Code Snippet</h3>
    <pre><code class="language-python">
import fastkde
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Extract minority class features and reduce dimensionality with PCA
minority_features = X_sampled[y_sampled == 1].values
pca = PCA(n_components=2)
minority_features_reduced = pca.fit_transform(minority_features)

# Generate synthetic samples within the bounds of the minority class distribution
lower_bound = minority_features_reduced.min(axis=0)
upper_bound = minority_features_reduced.max(axis=0)
testpoints = np.random.uniform(low=lower_bound, high=upper_bound, size=(10000, 2))

# Calculate the density of points using FastKDE
pdf = fastkde.pdf_at_points(
    minority_features_reduced[:, 0], 
    minority_features_reduced[:, 1], 
    list_of_points=testpoints, 
    num_points=2**9 + 1
)

# Select the high-density points to create synthetic samples
fakes = testpoints[pdf > np.percentile(pdf, 65)]
fakes_original_space = pca.inverse_transform(fakes)

# Concatenate synthetic samples with the original dataset
X_fakes = np.row_stack([X_sampled, fakes_original_space])
y_fakes = np.concatenate([y_sampled, np.ones(len(fakes))])

# Split the dataset and train the classifier
X_train, X_test, y_train, y_test = train_test_split(X_fakes, y_fakes, test_size=0.2, random_state=42, stratify=y_fakes)
fastkdeclassifier = KNeighborsClassifier()
fastkdeclassifier.fit(X_train, y_train)
y_pred = fastkdeclassifier.predict(X_test)

# Display the classification report and confusion matrix
print(classification_report(y_test, y_pred))

cm_kde = confusion_matrix(y_test, y_pred)
sns.heatmap(cm_kde, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
    </code></pre>

    <h3>Results</h3>
    <p>The accuracy achieved with FastKDE-based synthetic data generation is <strong>96.01%</strong>. This approach allows the model to achieve a higher recall for the minority class by generating realistic synthetic samples. Here are the detailed metrics:</p>

    <pre><code class="language-text">
              precision    recall  f1-score   support

         0.0       0.96      1.00      0.98     22941
         1.0       0.98      0.46      0.62      1568

    accuracy                           0.96     24509
   macro avg       0.97      0.73      0.80     24509
weighted avg       0.97      0.96      0.96     24509
    </code></pre>

  
    <h3>Confusion Matrix</h3>
    <p>The confusion matrix below shows that the FastKDE-based classifier performs better on the minority class while maintaining high accuracy for the majority class.</p>
    <img src="Images/confusion_matrix (4).png" alt="FastKDE Confusion Matrix" width="500">

<h2>Implementing Normalizing Flows for Class Imbalance</h2>
    <p>
        Normalizing Flows provide a probabilistic method to model complex distributions by transforming simple base distributions using a series of invertible transformations. 
        In this application, we used a RealNVP-based Normalizing Flow model to oversample the minority class in the Porto Seguro dataset. The model learns to map the minority 
        class distribution effectively, helping to generate synthetic samples conditioned on the class label. This technique addresses class imbalance without traditional 
        oversampling techniques like SMOTE or ADASYN.
    </p>

    <h3>Code Implementation</h3>
    <pre><code class="language-python">
import torch
import torch.optim as optim
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
from torch.utils.data import DataLoader, TensorDataset
from nflows.transforms import MaskedAffineAutoregressiveTransform, CompositeTransform, ReversePermutation
from nflows.distributions import ConditionalDiagonalNormal
from nflows.flows import Flow
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Preprocess the dataset
scaler = MinMaxScaler()
X_sampled_scaled = scaler.fit_transform(X_sampled)
X_sampled_tensor = torch.tensor(X_sampled_scaled, dtype=torch.float32).to(device)
y_sampled_tensor = torch.tensor(y_sampled.values, dtype=torch.float32).reshape(-1, 1).to(device)

# Define Normalizing Flow model
num_features = X_sampled_tensor.shape[1]
num_layers = 10
hidden_features = 8
learning_rate = 0.001
num_epochs = 20

# Base distribution with conditioning
base_dist = ConditionalDiagonalNormal(shape=[num_features], context_encoder=nn.Linear(1, 2 * num_features))

# Flow transformations
transforms = []
for _ in range(num_layers):
    transforms.append(ReversePermutation(features=num_features))
    transforms.append(MaskedAffineAutoregressiveTransform(features=num_features, hidden_features=hidden_features, context_features=1))

transform = CompositeTransform(transforms)
flow = Flow(transform, base_dist).to(device)

# Optimizer
optimizer = optim.Adam(flow.parameters(), lr=learning_rate)

# Training loop
for epoch in range(num_epochs):
    flow.train()
    epoch_loss = 0
    for x_batch, y_batch in data_loader:
        optimizer.zero_grad()
        loss = -flow.log_prob(inputs=x_batch, context=y_batch).mean()
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item() * x_batch.size(0)
    epoch_loss /= len(dataset)
    print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}")

# Evaluation
flow.eval()
with torch.no_grad():
    x_ = X_sampled_tensor
    hyp_0 = torch.zeros_like(y_sampled_tensor).to(device)
    hyp_1 = torch.ones_like(y_sampled_tensor).to(device)

    LL_class_0 = flow.log_prob(x_, context=hyp_0).cpu().numpy()
    LL_class_1 = flow.log_prob(x_, context=hyp_1).cpu().numpy()

# Make predictions based on higher log-likelihood
y_pred = np.zeros_like(y_sampled)
y_pred[LL_class_1 > LL_class_0] = 1

# Confusion Matrix
conf_matrix = confusion_matrix(y_sampled, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=[0, 1], yticklabels=[0, 1])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

accuracy = (y_pred == y_sampled).sum() * 100 / len(y_sampled)
precision = precision_score(y_sampled, y_pred, average=None)
recall = recall_score(y_sampled, y_pred, average=None)

print(f"Accuracy: {accuracy:.2f}%")
print(f"Precision for class 0: {precision[0]:.2f}")
print(f"Precision for class 1: {precision[1]:.2f}")
print(f"Recall for class 0: {recall[0]:.2f}")
print(f"Recall for class 1: {recall[1]:.2f}")
    </code></pre>

    <h3>Results</h3>
    <p>The results indicate an accuracy of <strong>62.02%</strong>. However, as expected with an imbalanced dataset, the recall for the minority class (class 1) is relatively low, while the model achieves a higher recall for the majority class (class 0). This outcome highlights the challenges of directly using a Normalizing Flow model for oversampling in a highly imbalanced context.</p>

    <pre><code class="language-text">
Epoch 1/20, Loss: 8.2839
...
Epoch 20/20, Loss: -38.6511
Accuracy: 62.02%
Precision for class 0: 0.97
Precision for class 1: 0.05
Recall for class 0: 0.62
Recall for class 1: 0.50
    </code></pre>

    <!-- Confusion Matrix Image -->
    <h3>Confusion Matrix</h3>
    <p>The confusion matrix below shows that the Normalizing Flow model is able to capture some instances of the minority class but primarily favors the majority class, which reflects the limitations of this method in achieving high recall for minority cases without additional balancing techniques.</p>
    <img src="Images/Screenshot%202024-11-11%20at%201.03.53%20PM.png" alt="Normalizing Flow Confusion Matrix" width="500">


</body>
</html>
