<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gradient Boosting in Locally Weighted Regression</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        h1, h2 {
            color: #2E86C1;
        }
        p {
            font-size: 1.1em;
        }
        .header {
            background-color: #f4f4f4;
            padding: 20px;
            border-radius: 10px;
        }
        .section {
            margin-top: 20px;
        }
    </style>
</head>
<body>

    <div class="header">
        <h1>Patrick Church</h1>
        <p>Class: Data 440</p>
        <p>Date: 9/26/24</p>
    </div>

    <div class="section">
        <h2>Gradient Boosting in Locally Weighted Regression</h2>
    </div>

    <div class="section">
        <h2>Patricks_Gradient_Boosted_LWR Class</h2>
        <p>
            The <strong>Patricks_Gradient_Boosted_LWR</strong> class is designed to implement gradient boosting in the context of Locally Weighted Regression (LWR). 
            This class introduces flexibility and customization for users by allowing them to specify the number of boosting iterations they would like to perform when 
            running the <code>cross_validate</code> function. Additionally, it provides an option for users to choose between three different standardization techniques: 
            <strong>QuantileScaler</strong>, <strong>MinMaxScaler</strong>, and <strong>StandardScaler</strong>. These scalers are key to ensuring that data is appropriately 
            scaled before running the regression models.
        </p>

        <h2>Key Features:</h2>
        <ul>
            <li><strong>User-Controlled Gradient Boosting:</strong>
                The user can control the number of boosting stages using the <code>n_boosts</code> argument in the <code>cross_validate</code> function. This flexibility 
                allows the user to customize how much the model iteratively refines the residuals through multiple boosting steps.
            </li>

            <li><strong>Choice of Standardization Method:</strong>
                The <code>cross_validate</code> function allows the user to choose between three different data standardization methods:
                <ul>
                    <li><strong>StandardScaler:</strong> Standardizes features by removing the mean and scaling to unit variance.</li>
                    <li><strong>MinMaxScaler:</strong> Scales features to a given range (usually between 0 and 1).</li>
                    <li><strong>QuantileScaler:</strong> Transforms features to follow a uniform or normal distribution.</li>
                </ul>
                The comparison between these scalers is a core feature of the class, as it shows how different data transformations impact model performance.
            </li>

            <li><strong>Cross-Validation and Model Comparison:</strong>
                The class uses <strong>10-fold cross-validation</strong> to train and test the locally weighted regression model. It compares the performance of the 
                <strong>Locally Weighted Regression</strong> model against the <strong>eXtreme Gradient Boosting (XGBoost)</strong> model. The cross-validation function computes the 
                <strong>Mean Squared Error (MSE)</strong> for both models and prints the results for direct comparison.
            </li>

            <li><strong>Competing with XGBoost:</strong>
                One of the primary goals of this class is to demonstrate that <strong>Locally Weighted Regression</strong> (when enhanced with gradient boosting) 
                can compete with the widely used <strong>XGBoost</strong> model. By refining the predictions through boosting and scaling the data appropriately, 
                the class shows how LWR can achieve comparable or better MSEs than XGBoost in regression tasks.
            </li>
        </ul>
    </div>


</body>
</html>
