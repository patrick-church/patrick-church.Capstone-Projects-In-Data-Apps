<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gradient Boosting in Locally Weighted Regression</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/components/prism-python.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        h1, h2 {
            color: #2E86C1;
        }
        p {
            font-size: 1.1em;
        }
        .header {
            background-color: #f4f4f4;
            padding: 20px;
            border-radius: 10px;
        }
        .section {
            margin-top: 20px;
        }
        pre {
            background: #f4f4f4;
            padding: 15px;
            border-radius: 5px;
        }
    </style>
</head>
<body>

    <div class="header">
        <h1>Patrick Church</h1>
        <p>Class: Data 440</p>
        <p>Date: 9/26/24</p>
    </div>

    <div class="section">
        <h2>Gradient Boosting in Locally Weighted Regression</h2>
    </div>

    <div class="section">
        <h2>Patricks_Gradient_Boosted_LWR Class</h2>
        <p>
            The <strong>Patricks_Gradient_Boosted_LWR</strong> class is designed to implement gradient boosting in the context of Locally Weighted Regression (LWR). 
            This class introduces flexibility and customization for users by allowing them to specify the number of boosting iterations they would like to perform when 
            running the <code>cross_validate</code> function. Additionally, it provides an option for users to choose between three different standardization techniques: 
            <strong>QuantileScaler</strong>, <strong>MinMaxScaler</strong>, and <strong>StandardScaler</strong>. These scalers are key to ensuring that data is appropriately 
            scaled before running the regression models.
        </p>

        <h2>Key Features:</h2>
        <ul>
            <li><strong>User-Controlled Gradient Boosting:</strong>
                The user can control the number of boosting stages using the <code>n_boosts</code> argument in the <code>cross_validate</code> function. This flexibility 
                allows the user to customize how much the model iteratively refines the residuals through multiple boosting steps.
            </li>

            <li><strong>Choice of Standardization Method:</strong>
                The <code>cross_validate</code> function allows the user to choose between three different data standardization methods:
                <ul>
                    <li><strong>StandardScaler:</strong> Standardizes features by removing the mean and scaling to unit variance.</li>
                    <li><strong>MinMaxScaler:</strong> Scales features to a given range (usually between 0 and 1).</li>
                    <li><strong>QuantileScaler:</strong> Transforms features to follow a uniform or normal distribution.</li>
                </ul>
                The comparison between these scalers is a core feature of the class, as it shows how different data transformations impact model performance.
            </li>

            <li><strong>Cross-Validation and Model Comparison:</strong>
                The class uses <strong>10-fold cross-validation</strong> to train and test the locally weighted regression model. It compares the performance of the 
                <strong>Locally Weighted Regression</strong> model against the <strong>eXtreme Gradient Boosting (XGBoost)</strong> model. The cross-validation function computes the 
                <strong>Mean Squared Error (MSE)</strong> for both models and prints the results for direct comparison.
            </li>

            <li><strong>Competing with XGBoost:</strong>
                One of the primary goals of this class is to demonstrate that <strong>Locally Weighted Regression</strong> (when enhanced with gradient boosting) 
                can compete with the widely used <strong>XGBoost</strong> model. By refining the predictions through boosting and scaling the data appropriately, 
                the class shows how LWR can achieve comparable or better MSEs than XGBoost in regression tasks.
            </li>
        </ul>
    </div>

    <div class="section">
        <h2>Python Class: Patricks_Gradient_Boosted_LWR</h2>
        <pre><code class="language-python">
            
class Patricks_Gradient_Boosted_LWR:
    def __init__(self, kernel=Gaussian, tau=4.0):
        self.kernel = kernel
        self.tau = tau
        self._is_fitted = False  # A flag to track if the model is fitted

    def fit(self, x, y):
        self.xtrain_ = x
        self.yhat_ = y
        self._is_fitted = True  # Set the flag to True after fitting the model

    def is_fitted(self):
        if not self._is_fitted:
            raise ValueError("This Lowess_2 instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.")

    def predict(self, x_new):
        # Check if the model is fitted
        self.is_fitted()

        x = self.xtrain_
        y = self.yhat_
        lm = Ridge(alpha=0.001)
        w = weight_function(x, x_new, self.kernel, self.tau)

        if np.isscalar(x_new):
            lm.fit(np.diag(w) @ (x.reshape(-1, 1)), np.diag(w) @ (y.reshape(-1, 1)))
            yest = lm.predict([[x_new]])[0][0]
        else:
            n = len(x_new)
            yest_test = []
            for i in range(n):
                lm.fit(np.diag(w[:, i]) @ x, np.diag(w[:, i]) @ y)
                yest_test.append(lm.predict(x_new[i].reshape(1, -1)))
        return np.array(yest_test).reshape(-1, 1)

    def boosted_lwr_more(self, x, y, xnew, n_boosts=3):
        model1 = Patricks_Gradient_Boosted_LWR(kernel=Gaussian, tau=0.35)
        model1.fit(x, y)
        predictions = model1.predict(xnew)

        residuals = y - model1.predict(x).ravel()

        for i in range(1, n_boosts):
            if i % 2 == 0:
                model = Patricks_Gradient_Boosted_LWR(kernel=Gaussian, tau=0.35)
            else:
                model = Patricks_Gradient_Boosted_LWR(kernel=Tricubic, tau=0.23)

            model.fit(x, residuals)
            predictions += model.predict(xnew)
            residuals -= model.predict(x).ravel()

        return predictions

    def cross_validate(self, X, y, scaling_method='standard', kfold_splits=10, seed=42, boost_rounds=3):

        if scaling_method == 'minmax':
            scaler = MinMaxScaler()
        elif scaling_method == 'quantile':
            scaler = QuantileTransformer(n_quantiles=900)
        else:
            scaler = StandardScaler()

        mse_lwr_results = []
        mse_xgb_results = []

        kfold = KFold(n_splits=kfold_splits, shuffle=True, random_state=seed)
        xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=100, reg_lambda=20, alpha=1, gamma=10, max_depth=7)

        for train_idx, test_idx in kfold.split(X):
            X_train = X[train_idx]
            y_train = y[train_idx]
            y_test = y[test_idx]
            X_test = X[test_idx]

            X_train = scaler.fit_transform(X_train)
            X_test = scaler.transform(X_test)

            y_pred_lwr = self.boosted_lwr_more(X_train, y_train, X_test, n_boosts=boost_rounds)

            xgb_model.fit(X_train, y_train)
            y_pred_xgb = xgb_model.predict(X_test)

            mse_lwr_results.append(mean_squared_error(y_test, y_pred_lwr))
            mse_xgb_results.append(mean_squared_error(y_test, y_pred_xgb))

        print(f'The Cross-validated Mean Squared Error for Locally Weighted Regression is: {np.mean(mse_lwr_results)}')
        print(f'The Cross-validated Mean Squared Error for XGBRegressor is: {np.mean(mse_xgb_results)}')
        </code></pre>
    </div>

    <div class="section">
        <h2>Function Summaries</h2>
        <ul>
            <li><strong>__init__(self, kernel=Gaussian, tau=0.03):</strong>
                This is the constructor that initializes the class. It sets the kernel (defaulting to Gaussian) and the tau parameter (a bandwidth parameter controlling the weight function). It also sets a flag, _is_fitted, to False, indicating that the model has not yet been trained.
            </li>
            <li><strong>fit(self, x, y):</strong>
                This method trains the model by storing the training data (x for features, y for target values) and setting the _is_fitted flag to True. It does not perform any actual fitting, but prepares the model with the data for later predictions.
            </li>
            <li><strong>is_fitted(self):</strong>
                This is a helper function that checks if the model has been fitted (trained). If the model has not been fitted, it raises a ValueError, ensuring that predictions are only made after the model has been trained.
            </li>
            <li><strong>predict(self, x_new):</strong>
                This method predicts the target values for new data (x_new) using the fitted model. It checks if the model is fitted using is_fitted(), computes the weights using a kernel function, and then applies ridge regression to make the predictions. If the input is scalar, it predicts a single value; otherwise, it predicts for multiple data points.
            </li>
            <li><strong>boosted_lwr_more(self, x, y, xnew, n_boosts=3):</strong>
                This function implements gradient boosting for locally weighted regression. It trains the model (Patricks_Gradient_Boosted_LWR) on the residuals in multiple boosting rounds (controlled by the n_boosts argument). Each boosting step fits a new model on the residual errors from the previous prediction and updates the overall prediction.
            </li>
            <li><strong>cross_validate(self, X, y, scaling_method='standard', kfold_splits=10, seed=42, boost_rounds=3):</strong>
                This function performs 10-fold cross-validation on the dataset, comparing the locally weighted regression model against the XGBoost model. It allows the user to choose between different scaling methods (StandardScaler, MinMaxScaler, QuantileScaler) and specify the number of boosting rounds (boost_rounds). The function computes the Mean Squared Error (MSE) for both models and prints the results.
            </li>
        </ul>
    </div>

    <div class="section">
    <h2>Application: Locally Weighted Regression with Gradient Boosting</h2>
    <p>
        The following examples demonstrate the application of the <strong>Patricks_Gradient_Boosted_LWR</strong> class, which implements 
        locally weighted regression (LWR) enhanced with gradient boosting. By leveraging multiple iterations of model fitting on residuals 
        and choosing the appropriate scaling method, we aim to show how LWR can perform competitively against models like XGBoost.
    </p>
    <p>
        In these examples, we compare the performance of LWR with gradient boosting using three different data scaling techniques:
        <strong>StandardScaler</strong>, <strong>MinMaxScaler</strong>, and <strong>QuantileScaler</strong>. Each standardization method affects 
        how the model weights and processes the data, influencing its predictive accuracy. We will show how the results differ and, in some cases, 
        how LWR can even outperform the XGBoost model when paired with the right scaling technique.
    </p>
    <p>
        Below, we present the results of cross-validation using the specified scalers, detailing the mean squared error (MSE) for each, 
        along with comparisons to XGBoost. These examples illustrate the effectiveness of gradient boosting in locally weighted regression and highlight 
        the importance of selecting an appropriate scaling method for optimal performance.
    </p>
    </div>

    <div class="section">
        <h2>Cross-Validation Using StandardScaler</h2>
        <pre><code class="language-python">model.cross_validate(X, y, 'standard', kfold_splits=10, boost_rounds=3)</code></pre>
        <p>When performing cross-validation using <strong>StandardScaler</strong>, we observe that the locally weighted regression (LWR) model performs significantly worse compared to the <strong>XGBoost</strong> model.</p>
        <p>The results are as follows:</p>
        <ul>
            <li><strong>The Cross-validated Mean Squared Error for Locally Weighted Regression:</strong> 37.89103575535156</li>
            <li><strong>The Cross-validated Mean Squared Error for XGBRegressor:</strong> 21.093093221361816</li>
        </ul>
        <p>This indicates that <strong>StandardScaler</strong> is not ideal for locally weighted regression in this scenario, as it leads to much higher errors. Meanwhile, the XGBoost model, which uses gradient boosting decision trees, is less affected by scaling and performs consistently better.</p>
        <p>This suggests that while locally weighted regression can benefit from gradient boosting, choosing the right scaler is crucial to achieving competitive results with models like XGBoost.</p>
    </div>


    <div class="section">
        <h2>Cross-Validation Using MinMaxScaler</h2>
        <pre><code class="language-python">model.cross_validate(X, y, 'minmax', kfold_splits=10, boost_rounds=3)</code></pre>
        <p>When using <strong>MinMaxScaler</strong> for cross-validation, the results for the locally weighted regression (LWR) model are even worse compared to XGBoost.</p>
        <p>The results are as follows:</p>
        <ul>
            <li><strong>The Cross-validated Mean Squared Error for Locally Weighted Regression:</strong> 43.774658824515555</li>
            <li><strong>The Cross-validated Mean Squared Error for XGBRegressor:</strong> 21.093093221361816</li>
        </ul>
        <p>In this case, the <strong>MinMaxScaler</strong> performs poorly for locally weighted regression, leading to the highest Mean Squared Error (MSE) among the scalers. The XGBoost model, on the other hand, maintains its performance with a much lower MSE, showing that tree-based models like XGBoost are less sensitive to scaling methods.</p>
        <p>These results highlight that choosing the appropriate scaling method is crucial for locally weighted regression, especially when competing with models like XGBoost.</p>
    </div>

    <div class="section">
    <h2>Cross-Validation Using QuantileScaler</h2>
    <pre><code class="language-python">model.cross_validate(X, y, 'quantile', kfold_splits=10, boost_rounds=3)</code></pre>
    <p>When using <strong>QuantileScaler</strong> with this set of parameters—<strong>kfold_splits=10</strong>, and <strong>boost_rounds=3</strong>—the locally weighted regression (LWR) model <strong>outperforms XGBoost</strong> in terms of Mean Squared Error (MSE).</p>
    <p>The results are as follows:</p>
    <ul>
        <li><strong>The Cross-validated Mean Squared Error for Locally Weighted Regression:</strong> 20.709935807739438</li>
        <li><strong>The Cross-validated Mean Squared Error for XGBRegressor:</strong> 21.093093221361816</li>
    </ul>
    <p>This performance boost can be attributed to the specific gradient boosting parameters used during training. For each boosting iteration, the following parameters were applied:</p>
    <pre><code class="language-python">
    for i in range(1, n_boosts):
        if i % 2 == 0:
            model = Patricks_Gradient_Boosted_LWR(kernel=Gaussian, tau=0.35)
        else:
            model = Patricks_Gradient_Boosted_LWR(kernel=Tricubic, tau=0.23)
    </code></pre>
    <p>In this gradient boosting scheme, the model alternates between using a <strong>Gaussian kernel with tau=0.35</strong> and a <strong>Tricubic kernel with tau=0.23</strong> for each boosting iteration. By alternating between these two kernel functions, the model successfully refines its predictions on the residuals at each stage.</p>
    <p>With the use of <strong>QuantileScaler</strong> and these specific kernel parameters, the locally weighted regression model is able to reduce its Mean Squared Error below that of the XGBoost model. This result emphasizes the power of combining the right scaling technique with an effective gradient boosting strategy.</p>
    </div>


    <div class="section">
    <h2>Comparing Locally Weighted Regression Approaches on the Iris Dataset</h2>
    <p>
        In this section, we will compare two different approaches to locally weighted regression using the well-known 
        <strong>Iris dataset</strong> from <strong>sklearn</strong>. This dataset contains 150 samples of iris flowers, with three different species as the target variable. 
        Our goal is to classify these species using locally weighted regression techniques.
    </p>
    <p>
        We will compare my custom <strong>Patricks_LWLR</strong> class, which implements locally weighted logistic regression, 
        and the <strong>Calvin Chi's Locally Weighted Logistic Regression</strong> method, both applied to the Iris dataset. 
        However, these two methods handle the classification problem differently due to the multiclass nature of the target variable.
    </p>
    <p>
        My <strong>Patricks_LWLR</strong> class uses a <strong>Softmax</strong> approach to predict all three classes in the target variable at once. 
        This allows the model to assign probabilities to each class for every data point, providing a complete multiclass classification in a single run.
    </p>
    <p>
        On the other hand, Calvin Chi's locally weighted logistic regression method is designed specifically for binary classification. 
        To handle the multiclass nature of the Iris dataset, we run his method twice: first, comparing the first class in the target variable to the second class, 
        and then comparing the first class to the third class. This binary classification approach allows us to break down the multiclass problem into a series of binary comparisons.
    </p>
    <p>
        By comparing these two approaches on the Iris dataset, we will explore the strengths and limitations of each method when applied to the same dataset, 
        particularly in how they handle multiclass classification differently. The results will showcase how <strong>Patricks_LWLR</strong> handles the full multiclass problem with Softmax, 
        while Calvin Chi's method tackles it through iterative binary classification comparisons.
    </p>
    </div>

    <div class="section">
    <h2>Patricks_LWLR: Locally Weighted Logistic Regression</h2>
    <p>
        The <strong>Patricks_LWLR</strong> class is a custom implementation of locally weighted logistic regression designed to handle multiclass classification problems. 
        This model applies logistic regression with weighting based on a kernel function, which determines the contribution of training points based on their distance 
        from the prediction point. The model is flexible, allowing the user to specify the <strong>kernel</strong> type, the <strong>tau</strong> parameter (which controls the bandwidth of the kernel), 
        and the number of target classes.
    </p>
    <p>
        The class features a powerful <strong>cross_validate</strong> method that allows users to evaluate the model through cross-validation. 
        The user can select a <strong>scaling method</strong> (Standard, MinMax, or Quantile), specify the number of <strong>cross-validation folds</strong>, 
        and choose whether or not to visualize the results with a 2D <strong>PCA scatter plot</strong>. During cross-validation, key metrics such as accuracy, precision, recall, 
        and F1-score are computed, and visualizations such as confusion matrices and bar charts help assess the model's performance.
    </p>

    <h3>Complete Class Definition</h3>
    <pre><code class="language-python">
class Patricks_LWLR:
    def __init__(self, kernel=Gaussian, tau=4.0, num_classes=3):
        self.kernel = kernel
        self.tau = tau
        self.num_classes = num_classes

    def fit(self, x, y):
        self.xtrain_ = np.array(x)
        self.ytrain_ = np.array(y)

    def predict(self, x_new):
        x = np.array(self.xtrain_)
        y = np.array(self.ytrain_)

        lm = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=1e-3)

        w = np.array(weight_function(x, x_new, self.kernel, self.tau))

        if np.isscalar(x_new):
            weighted_x = x * w[:, None]
            lm.fit(weighted_x, y)
            yest = lm.predict([[x_new]])[0]
        else:
            n = len(x_new)
            yest_test = []
            for i in range(n):
                weighted_x = x * w[:, i][:, None]
                lm.fit(weighted_x, y)
                yest_test.append(lm.predict(x_new[i].reshape(1, -1)))

        return np.array(yest_test).reshape(-1, 1)

    def cross_validate(self, X, y, scaling_method='standard', kfold_splits=5, seed=42, visualize_pca=False):
        
        y = np.array(y).astype(int).ravel()

        if scaling_method == 'minmax':
            scaler = MinMaxScaler()
        elif scaling_method == 'quantile':
            scaler = QuantileTransformer(n_quantiles=900)
        else:
            scaler = StandardScaler()

        accuracy_results = []
        precision_results = []
        recall_results = []
        f1_results = []
        y_true_all = []
        y_pred_all = []

        kfold = KFold(n_splits=kfold_splits, shuffle=True, random_state=seed)

        for train_idx, test_idx in kfold.split(X):
            X_train = X[train_idx]
            y_train = y[train_idx]
            y_test = y[test_idx]
            X_test = X[test_idx]

            X_train = scaler.fit_transform(X_train)
            X_test = scaler.transform(X_test)

            self.fit(X_train, y_train)
            y_pred = self.predict(X_test).ravel()
            y_true_all.extend(y_test)
            y_pred_all.extend(y_pred)

            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='macro')
            recall = recall_score(y_test, y_pred, average='macro')
            f1 = f1_score(y_test, y_pred, average='macro')

            accuracy_results.append(accuracy)
            precision_results.append(precision)
            recall_results.append(recall)
            f1_results.append(f1)

        print(f'Average Accuracy: {np.mean(accuracy_results):.4f}')
        print(f'Average Precision: {np.mean(precision_results):.4f}')
        print(f'Average Recall: {np.mean(recall_results):.4f}')
        print(f'Average F1-Score: {np.mean(f1_results):.4f}')

        self.plot_confusion_matrix(np.array(y_true_all), np.array(y_pred_all))
        self.plot_metrics_bar(accuracy_results, precision_results, recall_results, f1_results)

        if visualize_pca:
            self.visualize_pca_2d(X, y_true_all, y_pred_all)

        return {
            'accuracy': np.mean(accuracy_results),
            'precision': np.mean(precision_results),
            'recall': np.mean(recall_results),
            'f1_score': np.mean(f1_results)
        }

    def plot_confusion_matrix(self, y_true, y_pred):
        cm = confusion_matrix(y_true, y_pred)
        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
        disp.plot(cmap='Blues')
        plt.title("Confusion Matrix")
        plt.show()

    def plot_metrics_bar(self, accuracies, precisions, recalls, f1_scores):
        metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
        avg_metrics = [np.mean(accuracies), np.mean(precisions), np.mean(recalls), np.mean(f1_scores)]

        plt.figure(figsize=(8, 6))
        plt.bar(metrics, avg_metrics, color=['blue', 'green', 'orange', 'red'])
        plt.ylim(0, 1)
        plt.title("Cross-Validation Metrics")
        plt.ylabel("Score")
        plt.show()

    def visualize_pca_2d(self, X, y_true, y_pred):
        pca = PCA(n_components=2)
        X_2d = pca.fit_transform(X)

        plt.figure(figsize=(8, 6))
        plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_true, cmap='viridis', marker='o', label='True Labels', alpha=0.6)
        plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_pred, cmap='cool', marker='x', label='Predicted Labels', alpha=0.6)
        plt.title('PCA Visualization: True vs Predicted Labels')
        plt.xlabel('Principal Component 1')
        plt.ylabel('Principal Component 2')
        plt.legend(loc='best')
        plt.show()
    </code></pre>

    <p>By running the <strong>cross_validate</strong> method, users can assess the performance of <strong>Patricks_LWLR</strong> on multiclass classification problems. The method supports flexible scaling options, allows for custom cross-validation settings, and includes the option to visualize results using PCA.</p>
    </div>




</body>
</html>
