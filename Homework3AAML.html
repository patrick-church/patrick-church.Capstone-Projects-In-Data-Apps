<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Patrick Church - Assignment 3</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #e0f7fa;
            margin: 0;
            padding: 0;
        }
        header {
            background-color: #0277bd;
            color: white;
            padding: 20px;
            text-align: center;
        }
        section {
            margin: 20px;
            padding: 20px;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        h1, h2 {
            color: #01579b;
        }
        p {
            font-size: 1.1em;
            line-height: 1.6;
            color: #333;
        }
        pre {
            background-color: #f4f4f4;
            padding: 10px;
            border-left: 5px solid #0277bd;
            overflow-x: auto;
            border-radius: 4px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }
        table, th, td {
            border: 1px solid #ccc;
        }
        th, td {
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #0288d1;
            color: white;
        }
        ul {
            color: #0277bd;
        }
    </style>
</head>
<body>

<header>
    <h1>Patrick Church - Assignment 3</h1>
    <p>October 9, 2024</p>
</header>

<section>
    <h2>SCAD Regularization and Variable Selection in PyTorch</h2>
    <p>
        This assignment involved implementing a PyTorch class that applies SCAD (smoothly clipped absolute deviation) regularization and variable selection for linear models. The implementation was based on the following references:
    </p>
    <ul>
        <li><a href="https://andrewcharlesjones.github.io/journal/scad.html" target="_blank">SCAD Method Overview</a></li>
        <li><a href="https://www.jstor.org/stable/27640214?seq=1" target="_blank">JSTOR SCAD Regularization</a></li>
    </ul>
    <p>
        The PyTorch class <code>SCADLinearModel</code> was developed to handle linear regression using SCAD regularization. The code includes a forward pass function, a SCAD penalty computation, and a custom loss function that combines mean squared error (MSE) with the SCAD penalty. Below is an example of the code implementation.
    </p>

    <h3>Class Implementation</h3>
    <pre><code class="language-python">
class SCADLinearModel(nn.Module):
    def __init__(self, input_dim, alpha=1.0, a=3.7, device="cpu"):
        super(SCADLinearModel, self).__init__()
        self.linear = nn.Linear(input_dim, 1).double()
        self.alpha = alpha
        self.a = a
        self.device = device
        self.to(device)

    def scad_penalty(self, beta_hat, lambda_val, a_val):
        abs_beta_hat = torch.abs(beta_hat)
        is_linear = abs_beta_hat <= lambda_val
        is_quadratic = (lambda_val < abs_beta_hat) & (abs_beta_hat <= a_val * lambda_val)
        is_constant = abs_beta_hat > a_val * lambda_val
        linear_part = lambda_val * abs_beta_hat * is_linear
        quadratic_part = (2 * a_val * lambda_val * abs_beta_hat - beta_hat**2 - lambda_val**2) / (2 * (a_val - 1)) * is_quadratic
        constant_part = (lambda_val**2 * (a_val + 1)) / 2 * is_constant
        return linear_part + quadratic_part + constant_part

    def forward(self, x):
        return self.linear(x)

    def compute_loss(self, predictions, targets):
        mse_loss = nn.functional.mse_loss(predictions, targets)
        scad_penalty = self.scad_penalty(self.linear.weight, self.alpha, self.a)
        return mse_loss + scad_penalty.sum()


# Testing on the concrete dataset
x = data.drop(columns = ['strength'])
y = data['strength']

x_train_np = x.to_numpy()
y_train_np = y.to_numpy()

x_train = torch.tensor(x_train_np, dtype=torch.double)
y_train = torch.tensor(y_train_np.reshape(-1, 1), dtype=torch.double)

model = SCADLinearModel(input_dim=x_train.shape[1], alpha=1.0, a=3.5, device="cpu")
    
optimizer = torch.optim.Adam(model.parameters(), lr=0.1)

num_epochs = 1000
for epoch in range(num_epochs):
    model.train()
        
    predictions = model(x_train)
        
    loss = model.compute_loss(predictions, y_train)
        
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
        
    if (epoch + 1) % 100 == 0:
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")
    
with torch.no_grad():
    weights = model.linear.weight.cpu().numpy()

feature_names = x.columns

feature_importance = list(zip(feature_names, weights[0]))  

print("\nAll Coefficients (Weights):")
print("--------------------------------")
for feature, weight in feature_importance:
    print(f"{feature:<14} : {weight:.6f}")
print("--------------------------------")

feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)

print("\nFeature Importance (sorted by absolute weight value):")
print("-----------------------------------------------------")
print("| Feature        |    Weight    |   Importance Rank  |")
print("-----------------------------------------------------")
for rank, (feature, weight) in enumerate(feature_importance, 1):
    print(f"| {feature:<14} |  {weight:>9.4f}   |        {rank:<2}          |")
print("-----------------------------------------------------")
    </code></pre>

    <h3>Feature Coefficients</h3>
    <table>
        <thead>
            <tr>
                <th>Feature</th>
                <th>Weight</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>cement</td>
                <td>0.114060</td>
            </tr>
            <tr>
                <td>slag</td>
                <td>0.096984</td>
            </tr>
            <tr>
                <td>ash</td>
                <td>0.080741</td>
            </tr>
            <tr>
                <td>water</td>
                <td>-0.183815</td>
            </tr>
            <tr>
                <td>superplastic</td>
                <td>0.237173</td>
            </tr>
            <tr>
                <td>coarseagg</td>
                <td>0.010150</td>
            </tr>
            <tr>
                <td>fineagg</td>
                <td>0.011910</td>
            </tr>
            <tr>
                <td>age</td>
                <td>0.113812</td>
            </tr>
        </tbody>
    </table>

    <h3>Feature Importance</h3>
    <table>
        <thead>
            <tr>
                <th>Feature</th>
                <th>Weight</th>
                <th>Importance Rank</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>superplastic</td>
                <td>0.2372</td>
                <td>1</td>
            </tr>
            <tr>
                <td>water</td>
                <td>-0.1838</td>
                <td>2</td>
            </tr>
            <tr>
                <td>cement</td>
                <td>0.1141</td>
                <td>3</td>
            </tr>
            <tr>
                <td>age</td>
                <td>0.1138</td>
                <td>4</td>
            </tr>
            <tr>
                <td>slag</td>
                <td>0.0970</td>
                <td>5</td>
            </tr>
            <tr>
                <td>ash</td>
                <td>0.0807</td>
                <td>6</td>
            </tr>
            <tr>
                <td>fineagg</td>
                <td>0.0119</td>
                <td>7</td>
            </tr>
            <tr>
                <td>coarseagg</td>
                <td>0.0102</td>
                <td>8</td>
            </tr>
        </tbody>
    </table>
</section>

<section>
    <h2>Dataset Generation and Comparison of Regularization Methods</h2>
    <p>
        Based on the simulation design explained in class, I generated 200 datasets where the input features exhibit a strong correlation structure (with a correlation coefficient of approximately 0.9). This high degree of correlation was designed to test the robustness of different regularization techniques, specifically ElasticNet, SqrtLasso, and SCAD, in approximating an ideal solution.
    </p>
    <p>
        In this experiment, I designed an ideal "betastar" with a chosen sparsity pattern. The goal was to check which method — ElasticNet, SqrtLasso, or SCAD — produces the best approximation of this "betastar."
    </p>
    <p>
        You will see the following implementations:
    </p>
    <ul>
        <li>
            **SCAD**: The SCAD implementation is already introduced in the <code>SCADLinearModel</code> class shown above. In this section, the SCAD regularization will be tested against the other two methods using the same generated datasets.
        </li>
        <li>
            **ElasticNet**: An <code>ElasticNet</code> class has been implemented, where both the L1 (lasso) and L2 (ridge) penalties are applied to the model to handle correlated features. You will see the implementation of the ElasticNet method and how it performs in approximating the betastar in the generated datasets.
        </li>
        <li>
            **SqrtLasso**: A <code>SqrtLasso</code> class is introduced that employs square-root Lasso regularization. The class includes the necessary adjustments to handle the highly correlated feature space and will be compared to the SCAD and ElasticNet methods.
        </li>
    </ul>

    <p>
        In the following sections, you will find the implementations of each of these regularization techniques, and their corresponding outputs when tested on the generated datasets.
    </p>
</section>

<section>
    <h2>Betastar Implementation in the SCAD Class</h2>
    <p>
        In this section, we demonstrate how the SCAD regularization method, implemented in the <code>SCADLinearModel</code> class, approximates a true sparse coefficient vector (<code>betastar</code>) across 200 simulated datasets. The following code shows the process of generating datasets with a strong correlation structure and a sparse true coefficient vector (<code>betastar</code>). We then train the SCAD model on these datasets to estimate the feature importance and compare the estimated coefficients to the true <code>betastar</code>.
    </p>
    
    <h3>Code for Dataset Generation and SCAD Training</h3>
    <pre><code class="language-python">
def mse_coefficients(betastar, estimated_coeffs):
    return np.mean((betastar - estimated_coeffs) ** 2)

def make_correlated_features(num_samples, p, rho, betastar, noise_std=0.1):
    vcor = [rho ** i for i in range(p)]
    r = toeplitz(vcor)
    mu = np.zeros(p)
    X = np.random.multivariate_normal(mu, r, size=num_samples)
    epsilon = np.random.normal(0, noise_std, size=(num_samples, 1))
    y = X @ betastar.reshape(-1, 1) + epsilon  
    return X, y

def create_betastar(p, sparsity_level):
    betastar = np.zeros(p)
    non_zero_indices = np.random.choice(p, sparsity_level, replace=False)
    betastar[non_zero_indices] = np.random.uniform(1, 5, size=sparsity_level)
    return betastar

rho = 0.9
p = 20
n = 150
num_datasets = 200
sparsity_level = 5
noise_std = 0.1

betastar = create_betastar(p, sparsity_level)
print("True betastar:", betastar)

datasets = [make_correlated_features(n, p, rho, betastar, noise_std) for _ in range(num_datasets)]

all_feature_importances = []  
all_losses = []  
mse_results = []  

for i, (X_train, y_train) in enumerate(datasets):
    x_train_tensor = torch.tensor(X_train, dtype=torch.double)
    y_train_tensor = torch.tensor(y_train, dtype=torch.double)

    model = SCADLinearModel(input_dim=p, alpha=1.0, a=3.5, device="cpu")
    optimizer = torch.optim.Adam(model.parameters(), lr=0.1)

    num_epochs = 1000
    for epoch in range(num_epochs):
        model.train()
        predictions = model(x_train_tensor)
        loss = model.compute_loss(predictions, y_train_tensor)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
    all_losses.append(loss.item())

    with torch.no_grad():
        weights = model.linear.weight.cpu().numpy()

    all_feature_importances.append(weights[0])

    mse = mse_coefficients(betastar, weights[0])
    mse_results.append(mse)

avg_feature_importance = np.mean(all_feature_importances, axis=0)

feature_names = [f'Feature {i+1}' for i in range(p)]

average_importance = list(zip(feature_names, avg_feature_importance))

average_importance.sort(key=lambda x: abs(x[1]), reverse=True)

print("Average Feature Importance (sorted by absolute weight value across 200 datasets):")
print("-----------------------------------------------------")
print("| Feature        |    Avg Weight   |   Importance Rank  |")
print("-----------------------------------------------------")
for rank, (feature, weight) in enumerate(average_importance, 1):
    print(f"| {feature:<14} |  {weight:>9.4f}     |        {rank:<2}          |")
print("-----------------------------------------------------")

avg_loss = np.mean(all_losses)
print(f"\nAverage Loss across 200 datasets: {avg_loss:.4f}")

avg_mse = np.mean(mse_results)
print(f"Average MSE between SCAD-estimated coefficients and betastar across 200 datasets: {avg_mse:.4f}")
    </code></pre>

    <h3>Explanation</h3>
    <p>
        This code performs the following:
    </p>
    <ul>
        <li><strong>MSE Calculation:</strong> The <code>mse_coefficients</code> function computes the mean squared error (MSE) between the true <code>betastar</code> and the estimated coefficients from the SCAD model. This measures how close the model’s estimates are to the true underlying values.</li>
        <li><strong>Generating Correlated Datasets:</strong> The <code>make_correlated_features</code> function generates datasets with a strong correlation structure between features (correlation of ~0.9) and adds some noise to simulate real-world data.</li>
        <li><strong>Creating Betastar:</strong> The <code>create_betastar</code> function creates a sparse coefficient vector, where only a few of the features are assigned non-zero values. This is the true signal that the SCAD model will attempt to recover.</li>
        <li><strong>Training the SCAD Model:</strong> The code then trains the SCAD model on each dataset for 1000 epochs, and after training, the estimated coefficients are compared to the true <code>betastar</code>.</li>
    </ul>

    <h3>Results</h3>
    <p>Here are the results from running the SCAD model on 200 datasets:</p>

    <h4>True Betastar</h4>
    <pre><code>True betastar: [0., 0., 0., 0., 0., 0., 0., 3.8197, 4.2420, 3.1721, 0., 0., 3.0342, 0., 4.6579, 0., 0., 0., 0., 0.]</code></pre>

    <h4>Average Feature Importance (sorted by absolute weight value across 200 datasets)</h4>
    <table>
        <thead>
            <tr>
                <th>Feature</th>
                <th>Average Weight</th>
                <th>Importance Rank</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>Feature 15</td><td>5.5484</td><td>1</td></tr>
            <tr><td>Feature 9</td><td>4.7952</td><td>2</td></tr>
            <tr><td>Feature 8</td><td>3.8178</td><td>3</td></tr>
            <tr><td>Feature 10</td><td>3.0063</td><td>4</td></tr>
            <tr><td>Feature 13</td><td>1.6533</td><td>5</td></tr>
            <tr><td>Feature 12</td><td>0.0088</td><td>6</td></tr>
            <tr><td>Feature 14</td><td>0.0063</td><td>7</td></tr>
            <tr><td>Feature 11</td><td>0.0053</td><td>8</td></tr>
            <tr><td>Feature 19</td><td>0.0019</td><td>9</td></tr>
            <tr><td>Feature 1</td><td>0.0017</td><td>10</td></tr>
            <tr><td>Feature 4</td><td>0.0011</td><td>11</td></tr>
            <tr><td>Feature 3</td><td>0.0010</td><td>12</td></tr>
            <tr><td>Feature 5</td><td>0.0009</td><td>13</td></tr>
            <tr><td>Feature 7</td><td>0.0009</td><td>14</td></tr>
            <tr><td>Feature 20</td><td>-0.0008</td><td>15</td></tr>
            <tr><td>Feature 18</td><td>-0.0007</td><td>16</td></tr>
            <tr><td>Feature 16</td><td>-0.0006</td><td>17</td></tr>
            <tr><td>Feature 2</td><td>0.0003</td><td>18</td></tr>
            <tr><td>Feature 17</td><td>0.0001</td><td>19</td></tr>
            <tr><td>Feature 6</td><td>0.0001</td><td>20</td></tr>
        </tbody>
    </table>

    <h4>Other Results</h4>
    <p>
        <strong>Average Loss:</strong> The average loss across the 200 datasets was <strong>11.0002</strong>. This value includes both the MSE and the SCAD penalty, showing how well the model fits the data while regularizing the coefficients.<br>
        <strong>Average MSE:</strong> The average mean squared error between the SCAD-estimated coefficients and the true <code>betastar</code> was <strong>0.3891</strong>, indicating that the SCAD model was able to approximate the true coefficients quite well.
    </p>
</section>


<section>
    <h2>Betastar Implementation in the ElasticNet Class</h2>
    <p>
        In this section, we describe the implementation of ElasticNet regularization using the <code>ElasticNet</code> class. ElasticNet is a combination of L1 (Lasso) and L2 (Ridge) regularization, controlled by the <code>l1_ratio</code> parameter, making it suitable for handling datasets with multicollinearity. The code below generates correlated datasets and trains the ElasticNet model to approximate the true <code>betastar</code> values across 200 datasets.
    </p>

    <h3>Code for ElasticNet Implementation and Dataset Generation</h3>
    <pre><code class="language-python">
class ElasticNet(nn.Module):
    def __init__(self, input_size, alpha=1.0, l1_ratio=0.5):
        super(ElasticNet, self).__init__()
        self.input_size = input_size
        self.alpha = alpha
        self.l1_ratio = l1_ratio

        self.linear = nn.Linear(input_size, 1).double()

    def forward(self, x):
        return self.linear(x)

    def loss(self, y_pred, y_true):
        mse_loss = nn.MSELoss()(y_pred, y_true)
        l1_reg = torch.norm(self.linear.weight, p=1)
        l2_reg = torch.norm(self.linear.weight, p=2)

        loss = mse_loss + self.alpha * (
            self.l1_ratio * l1_reg + (1 - self.l1_ratio) * l2_reg
        )

        return loss

    def fit(self, X, y, num_epochs=1000, learning_rate=0.01):
        optimizer = optim.SGD(self.parameters(), lr=learning_rate)

        for epoch in range(num_epochs):
            self.train()
            optimizer.zero_grad()
            y_pred = self(X)
            loss = self.loss(y_pred, y)
            loss.backward()
            optimizer.step()

    def predict(self, X):
        self.eval()
        with torch.no_grad():
            y_pred = self(X)
        return y_pred

    def get_coefficients(self):
        return self.linear.weight

def mse_coefficients(betastar, estimated_coeffs):
    return np.mean((betastar - estimated_coeffs) ** 2)

def make_correlated_features(num_samples, p, rho, betastar, noise_std=0.1):
    vcor = [rho ** i for i in range(p)]
    r = toeplitz(vcor)
    mu = np.zeros(p)
    X = np.random.multivariate_normal(mu, r, size=num_samples)
    epsilon = np.random.normal(0, noise_std, size=(num_samples, 1))
    y = X @ betastar.reshape(-1, 1) + epsilon  
    return X, y

def create_betastar(p, sparsity_level):
    betastar = np.zeros(p)
    non_zero_indices = np.random.choice(p, sparsity_level, replace=False)
    betastar[non_zero_indices] = np.random.uniform(1, 5, size=sparsity_level)
    return betastar

rho = 0.9
p = 20
n = 150
num_datasets = 200
sparsity_level = 5
noise_std = 0.1

betastar = create_betastar(p, sparsity_level)
print("True betastar:", betastar)

datasets = [make_correlated_features(n, p, rho, betastar, noise_std) for _ in range(num_datasets)]

all_feature_importances = [] 
all_losses = []  
mse_results = []  

for i, (X_train, y_train) in enumerate(datasets):
    
    x_train_tensor = torch.tensor(X_train, dtype=torch.double)
    y_train_tensor = torch.tensor(y_train, dtype=torch.double)

    
    model = ElasticNet(input_size=p, alpha=1.0, l1_ratio=0.5)  
    model.fit(x_train_tensor, y_train_tensor, num_epochs=1000, learning_rate=0.01)

    with torch.no_grad():
        estimated_coeffs = model.get_coefficients().cpu().numpy().flatten()

    all_feature_importances.append(estimated_coeffs)

    mse = mse_coefficients(betastar, estimated_coeffs)
    mse_results.append(mse)

    final_loss = model.loss(model.predict(x_train_tensor), y_train_tensor).item()
    all_losses.append(final_loss)

avg_feature_importance = np.mean(all_feature_importances, axis=0)

feature_names = [f'Feature {i+1}' for i in range(p)]

average_importance = list(zip(feature_names, avg_feature_importance))

average_importance.sort(key=lambda x: abs(x[1]), reverse=True)

print("Average Feature Importance (sorted by absolute weight value across 200 datasets):")
print("-----------------------------------------------------")
print("| Feature        |    Avg Weight   |   Importance Rank  |")
print("-----------------------------------------------------")
for rank, (feature, weight) in enumerate(average_importance, 1):
    print(f"| {feature:<14} |  {weight:>9.4f}     |        {rank:<2}          |")
print("-----------------------------------------------------")

avg_loss = np.mean(all_losses)
print(f"\nAverage Loss across 200 datasets: {avg_loss:.4f}")

avg_mse = np.mean(mse_results)
print(f"Average MSE between ElasticNet-estimated coefficients and betastar across 200 datasets: {avg_mse:.4f}")
    </code></pre>

    <h3>Explanation</h3>
    <p>
        The <code>ElasticNet</code> class is designed to combine both L1 (Lasso) and L2 (Ridge) regularization terms. By adjusting the <code>l1_ratio</code> parameter, we can control the contribution of L1 vs L2 regularization. This method is particularly useful for handling datasets with multicollinearity.
    </p>
    <ul>
        <li><strong>ElasticNet Loss Function:</strong> The loss function combines MSE with a penalty that is a weighted sum of the L1 and L2 norms of the coefficients. This helps regularize the model and prevent overfitting, especially in datasets with correlated features.</li>
        <li><strong>Dataset Generation:</strong> Similar to the SCAD implementation, we generate 200 datasets with a strong correlation structure and apply the ElasticNet model to estimate the coefficients.</li>
        <li><strong>Betastar:</strong> The true coefficients vector <code>betastar</code> is generated with sparsity, which the ElasticNet model attempts to recover.</li>
    </ul>

    <h3>Results</h3>
    <p>Here are the results from running the ElasticNet model on 200 datasets:</p>

    <h4>True Betastar</h4>
    <pre><code>True betastar: [3.2384, 0., 0., 0., 1.3742, 0., 0., 3.4213, 0., 0., 0., 0., 0., 0., 1.3335, 0., 1.5703, 0., 0., 0.]</code></pre>

    <h4>Average Feature Importance (sorted by absolute weight value across 200 datasets)</h4>
    <table>
        <thead>
            <tr>
                <th>Feature</th>
                <th>Average Weight</th>
                <th>Importance Rank</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>Feature 1</td><td>2.3248</td><td>1</td></tr>
            <tr><td>Feature 8</td><td>2.1266</td><td>2</td></tr>
            <tr><td>Feature 17</td><td>0.9840</td><td>3</td></tr>
            <tr><td>Feature 15</td><td>0.8481</td><td>4</td></tr>
            <tr><td>Feature 5</td><td>0.8416</td><td>5</td></tr>
            <tr><td>Feature 7</td><td>0.5500</td><td>6</td></tr>
            <tr><td>Feature 2</td><td>0.5407</td><td>7</td></tr>
            <tr><td>Feature 9</td><td>0.4709</td><td>8</td></tr>
            <tr><td>Feature 16</td><td>0.4080</td><td>9</td></tr>
            <tr><td>Feature 6</td><td>0.2967</td><td>10</td></tr>
            <tr><td>Feature 4</td><td>0.2207</td><td>11</td></tr>
            <tr><td>Feature 14</td><td>0.1806</td><td>12</td></tr>
            <tr><td>Feature 18</td><td>0.1596</td><td>13</td></tr>
            <tr><td>Feature 3</td><td>0.1358</td><td>14</td></tr>
            <tr><td>Feature 10</td><td>0.0849</td><td>15</td></tr>
            <tr><td>Feature 13</td><td>0.0424</td><td>16</td></tr>
            <tr><td>Feature 12</td><td>0.0292</td><td>17</td></tr>
            <tr><td>Feature 11</td><td>0.0272</td><td>18</td></tr>
            <tr><td>Feature 19</td><td>0.0177</td><td>19</td></tr>
            <tr><td>Feature 20</td><td>0.0081</td><td>20</td></tr>
        </tbody>
    </table>

    <h4>Other Results</h4>
    <p>
        <strong>Average Loss:</strong> The average loss across the 200 datasets was <strong>7.5427</strong>, indicating how well the model fits the data while regularizing the coefficients.<br>
        <strong>Average MSE:</strong> The average mean squared error between the ElasticNet-estimated coefficients and the true <code>betastar</code> was <strong>0.2379</strong>, showing that the ElasticNet model was effective in approximating the true coefficients.
    </p>
</section>

<section>
    <h2>Betastar Implementation in the SqrtLasso Class</h2>
    <p>
        This section demonstrates the implementation of the SqrtLasso regression model using the <code>sqrtLasso</code> class. SqrtLasso is designed to minimize the square root of the mean squared error (MSE) combined with an L1 regularization term, which helps identify important features while controlling for overfitting. The following code generates correlated datasets, trains the SqrtLasso model, and estimates the coefficients to approximate the true <code>betastar</code> across 200 datasets.
    </p>

    <h3>Code for SqrtLasso Implementation and Dataset Generation</h3>
    <pre><code class="language-python">
class sqrtLasso(nn.Module):
    def __init__(self, input_size, alpha=0.1):
        """
        Initialize the SqrtLasso regression model.
        Args:
            input_size (int): Number of input features.
            alpha (float): Regularization strength for L1 penalty.
        """
        super(sqrtLasso, self).__init__()
        self.input_size = input_size
        self.alpha = alpha

        self.linear = nn.Linear(input_size, 1).double()

    def forward(self, x):
        return self.linear(x)

    def loss(self, y_pred, y_true):
        mse_loss = nn.MSELoss()(y_pred, y_true)
        l1_reg = torch.norm(self.linear.weight, p=1, dtype=torch.float64)

        loss = (len(y_true) * mse_loss)**(1 / 2) + self.alpha * l1_reg
        return loss

    def fit(self, X, y, num_epochs=200, learning_rate=0.01):
        optimizer = optim.Adam(self.parameters(), lr=learning_rate)
        for epoch in range(num_epochs):
            self.train()
            optimizer.zero_grad()
            y_pred = self(X)
            loss = self.loss(y_pred, y)
            loss.backward()
            optimizer.step()

    def predict(self, X):
        self.eval()
        with torch.no_grad():
            y_pred = self(X)
        return y_pred

    def get_coefficients(self):
        return self.linear.weight

def mse_coefficients(betastar, estimated_coeffs):
    return np.mean((betastar - estimated_coeffs) ** 2)

def make_correlated_features(num_samples, p, rho, betastar, noise_std=0.1):
    vcor = [rho ** i for i in range(p)]
    r = toeplitz(vcor)
    mu = np.zeros(p)
    X = np.random.multivariate_normal(mu, r, size=num_samples)
    epsilon = np.random.normal(0, noise_std, size=(num_samples, 1))
    y = X @ betastar.reshape(-1, 1) + epsilon  
    return X, y

def create_betastar(p, sparsity_level):
    betastar = np.zeros(p)
    non_zero_indices = np.random.choice(p, sparsity_level, replace=False)
    betastar[non_zero_indices] = np.random.uniform(1, 5, size=sparsity_level)
    return betastar

rho = 0.9
p = 20
n = 150
num_datasets = 200
sparsity_level = 5
noise_std = 0.1

betastar = create_betastar(p, sparsity_level)
print("True betastar:", betastar)

datasets = [make_correlated_features(n, p, rho, betastar, noise_std) for _ in range(num_datasets)]

all_feature_importances = []  
all_losses = []  
mse_results = []  

for i, (X_train, y_train) in enumerate(datasets):
    x_train_tensor = torch.tensor(X_train, dtype=torch.double)
    y_train_tensor = torch.tensor(y_train, dtype=torch.double)

    model = sqrtLasso(input_size=p, alpha=0.1)  
    model.fit(x_train_tensor, y_train_tensor, num_epochs=200, learning_rate=0.01)

    with torch.no_grad():
        estimated_coeffs = model.get_coefficients().cpu().numpy().flatten()

    all_feature_importances.append(estimated_coeffs)

    mse = mse_coefficients(betastar, estimated_coeffs)
    mse_results.append(mse)

    final_loss = model.loss(model.predict(x_train_tensor), y_train_tensor).item()
    all_losses.append(final_loss)

avg_feature_importance = np.mean(all_feature_importances, axis=0)

feature_names = [f'Feature {i+1}' for i in range(p)]

average_importance = list(zip(feature_names, avg_feature_importance))

average_importance.sort(key=lambda x: abs(x[1]), reverse=True)

print("Average Feature Importance (sorted by absolute weight value across 200 datasets):")
print("-----------------------------------------------------")
print("| Feature        |    Avg Weight   |   Importance Rank  |")
print("-----------------------------------------------------")
for rank, (feature, weight) in enumerate(average_importance, 1):
    print(f"| {feature:<14} |  {weight:>9.4f}     |        {rank:<2}          |")
print("-----------------------------------------------------")

avg_loss = np.mean(all_losses)
print(f"\nAverage Loss across 200 datasets: {avg_loss:.4f}")

avg_mse = np.mean(mse_results)
print(f"Average MSE between SqrtLasso-estimated coefficients and betastar across 200 datasets: {avg_mse:.4f}")
    </code></pre>

    <h3>Explanation</h3>
    <p>
        The <code>sqrtLasso</code> class is designed to minimize the square root of the MSE combined with an L1 regularization term. This method penalizes large coefficients, encouraging sparsity and improving feature selection.
    </p>
    <ul>
        <li><strong>SqrtLasso Loss Function:</strong> The loss function takes the square root of the MSE and adds the L1 norm of the coefficients multiplied by the regularization strength (<code>alpha</code>).</li>
        <li><strong>Dataset Generation:</strong> Similar to the other methods, we generate 200 datasets with a strong correlation structure and train the SqrtLasso model to estimate the coefficients and approximate the true <code>betastar</code>.</li>
        <li><strong>Betastar:</strong> The true coefficients vector <code>betastar</code> is generated with sparsity, and the model attempts to recover these sparse features.
    </ul>

    <h3>Results</h3>
    <p>Here are the results from running the SqrtLasso model on 200 datasets:</p>

    <h4>True Betastar</h4>
    <pre><code>True betastar: [3.2080, 0., 0., 0., 0., 0., 0., 0., 4.4330, 0., 1.4908, 0., 0., 4.0839, 0., 1.5071, 0., 0., 0., 0.]</code></pre>

    <h4>Average Feature Importance (sorted by absolute weight value across 200 datasets)</h4>
    <table>
        <thead>
            <tr>
                <th>Feature</th>
                <th>Average Weight</th>
                <th>Importance Rank</th>
            </tr>
        </thead>
        <tbody>
            <tr><td>Feature 1</td><td>1.3504</td><td>1</td></tr>
            <tr><td>Feature 14</td><td>1.3304</td><td>2</td></tr>
            <tr><td>Feature 9</td><td>1.2933</td><td>3</td></tr>
            <tr><td>Feature 11</td><td>1.1128</td><td>4</td></tr>
            <tr><td>Feature 10</td><td>1.1126</td><td>5</td></tr>
            <tr><td>Feature 13</td><td>1.0893</td><td>6</td></tr>
            <tr><td>Feature 15</td><td>1.0616</td><td>7</td></tr>
            <tr><td>Feature 12</td><td>1.0084</td><td>8</td></tr>
            <tr><td>Feature 16</td><td>0.9378</td><td>9</td></tr>
            <tr><td>Feature 8</td><td>0.8885</td><td>10</td></tr>
            <tr><td>Feature 2</td><td>0.7939</td><td>11</td></tr>
            <tr><td>Feature 7</td><td>0.5572</td><td>12</td></tr>
            <tr><td>Feature 17</td><td>0.5300</td><td>13</td></tr>
            <tr><td>Feature 3</td><td>0.4354</td><td>14</td></tr>
            <tr><td>Feature 6</td><td>0.3195</td><td>15</td></tr>
            <tr><td>Feature 18</td><td>0.2425</td><td>16</td></tr>
            <tr><td>Feature 4</td><td>0.2412</td><td>17</td></tr>
            <tr><td>Feature 5</td><td>0.2274</td><td>18</td></tr>
            <tr><td>Feature 20</td><td>-0.0470</td><td>19</td></tr>
            <tr><td>Feature 19</td><td>0.0437</td><td>20</td></tr>
        </tbody>
    </table>

    <h4>Other Results</h4>
    <p>
        <strong>Average Loss:</strong> The average loss across the 200 datasets was <strong>22.8629</strong>, which shows the overall fit of the model while penalizing large coefficients.<br>
        <strong>Average MSE:</strong> The average MSE between the SqrtLasso-estimated coefficients and the true <code>betastar</code> was <strong>1.4375</strong>, indicating that the model was moderately effective in approximating the true coefficients.
    </p>
</section>

<section>
    <h2>Variable Selection Using SCAD, ElasticNet, and SqrtLasso for the Concrete Dataset with Quadratic Interaction Terms</h2>
    <p>
        In this section, I applied the three methods implemented above—SCAD, ElasticNet, and SqrtLasso—to the Concrete dataset, including quadratic interaction terms (polynomial features of degree 2). The goal is to determine the ideal model size (the number of variables with non-zero weights) and the cross-validated mean square error (MSE) for each method. Additionally, I will evaluate and compare these models to choose the best one.
    </p>

    <h3>Overview of the Process</h3>
    <p>
        Each method was used to perform variable selection on the Concrete dataset, including interaction terms. Polynomial features of degree 2 were generated to include quadratic interactions between variables, resulting in a more complex feature set. For each method, the following process was followed:
    </p>
    <ol>
        <li>Generate quadratic interaction terms for the dataset using polynomial features.</li>
        <li>Apply the respective method (SCAD, ElasticNet, or SqrtLasso) to perform variable selection and fit the model.</li>
        <li>Tune the regularization parameter (penalty weight) to find the best fit.</li>
        <li>Evaluate the model by calculating the ideal model size (number of non-zero coefficients) and cross-validated MSE.</li>
    </ol>
<section>

<section>
<section>
    <h2>SCAD Cross-Validation on Concrete Dataset</h2>

    <pre><code class="language-python">
def cross_validate_scad(X, y, alphas, num_folds=10, num_epochs=1000, learning_rate=0.1):
    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)
    best_alpha = None
    best_mse = float('inf')
    best_model = None
    all_fold_mses = []

    for alpha in alphas:
        fold_mses = []
        for train_index, val_index in kf.split(X):
            X_train, X_val = X[train_index], X[val_index]
            y_train, y_val = y[train_index], y[val_index]

            X_train_tensor = torch.tensor(X_train, dtype=torch.double)
            y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.double)
            X_val_tensor = torch.tensor(X_val, dtype=torch.double)
            y_val_tensor = torch.tensor(y_val.reshape(-1, 1), dtype=torch.double)

            model = SCADLinearModel(input_dim=X_train.shape[1], alpha=alpha, a=6.0)  
            optimizer = optim.Adam(model.parameters(), lr=learning_rate)

            for epoch in range(num_epochs):
                model.train()
                predictions = model(X_train_tensor)
                loss = model.compute_loss(predictions, y_train_tensor)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

            model.eval()
            with torch.no_grad():
                val_predictions = model(X_val_tensor)
                val_mse = nn.functional.mse_loss(val_predictions, y_val_tensor).item()
                fold_mses.append(val_mse)

        avg_mse = np.mean(fold_mses)
        all_fold_mses.append((alpha, avg_mse))
        print(f"Alpha: {alpha}, Validation MSE: {avg_mse:.4f}")

        if avg_mse < best_mse:
            best_mse = avg_mse
            best_alpha = alpha
            best_model = model.state_dict()  

    return best_alpha, best_mse, all_fold_mses, best_model


X = data.drop(columns=['strength'])
y = data['strength']
scaler = StandardScaler()
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X)
X_scaled = scaler.fit_transform(X_poly)
X_np = X_scaled
y_np = y.to_numpy()
alphas = [0.1, 0.5]
best_alpha, best_mse, all_fold_mses, best_model = cross_validate_scad(X_np, y_np, alphas, num_epochs=1000)

print(f"\nBest Alpha: {best_alpha}, Best Cross-Validated MSE: {best_mse:.4f}")

model = SCADLinearModel(input_dim=X_np.shape[1], alpha=best_alpha, a=6.0)
model.load_state_dict(best_model)
with torch.no_grad():
    coefficients = model.linear.weight.cpu().numpy().flatten()
non_zero_weights = np.sum(np.abs(coefficients) > 1e-1)  

print(f"Ideal Model Size (number of variables with non-zero weights): {non_zero_weights}")
print(f"Cross-Validated MSEs across all folds: {all_fold_mses}")
print(f"Coefficients: {coefficients}")
    </code></pre>

    <h3>Results</h3>
    <ul>
        <li><strong>Alpha: 0.1, Validation MSE:</strong> 62.2146</li>
        <li><strong>Alpha: 0.5, Validation MSE:</strong> 64.7830</li>
        <li><strong>Best Alpha:</strong> 0.1</li>
        <li><strong>Best Cross-Validated MSE:</strong> 62.2146</li>
        <li><strong>Ideal Model Size (number of variables with non-zero weights):</strong> 30</li>
        <li><strong>Full Coefficients:</strong></li>
    </ul>

    <pre><code>
[ 3.51625223e+00  5.90980969e-03  2.54634372e-03  6.34846373e-03
 -3.21755552e-03 -1.21320417e-03 -6.34329476e-03  3.77546214e+00
 -9.13997494e-01 -3.04055551e-02  1.30768368e+00 -2.82085435e+00
  3.44012144e-04  6.76324614e+00  4.43820697e+00  9.16117869e-01
 -2.09831236e+00  2.94420754e-01  3.42707385e-03  9.25981210e-01
  3.31988681e-03  7.66493721e+00  1.74805940e+00 -1.69972381e+00
 -3.59669837e+00 -1.59258162e+00 -1.23824640e-02  7.08911905e+00
  1.55635115e+00  4.37939401e+00  1.10249413e+00 -7.64892674e+00
  4.34308998e-04  3.35726475e+00 -4.06508145e+00  2.96202302e+00
  9.93867878e-04  1.92966949e+00 -2.63841392e-03  4.84427814e+00
  2.10170128e+00 -7.00798100e+00  6.75246514e+00 -1.25554953e+01]
    </code></pre>
</section>

<section>
    <h2>ElasticNet Cross-Validation on Concrete Dataset</h2>

    <pre><code class="language-python">
def cross_validate_elasticnet(X, y, alphas, l1_ratios, num_folds=5, num_epochs=1000, learning_rate=0.01):
    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)
    best_alpha = None
    best_l1_ratio = None
    best_mse = float('inf')
    best_model = None
    all_fold_mses = []

    for alpha in alphas:
        for l1_ratio in l1_ratios:
            fold_mses = []
            for train_index, val_index in kf.split(X):
                X_train, X_val = X[train_index], X[val_index]
                y_train, y_val = y[train_index], y[val_index]

                X_train_tensor = torch.tensor(X_train, dtype=torch.double)
                y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.double)
                X_val_tensor = torch.tensor(X_val, dtype=torch.double)
                y_val_tensor = torch.tensor(y_val.reshape(-1, 1), dtype=torch.double)


                model = ElasticNet(input_size=X_train.shape[1], alpha=alpha, l1_ratio=l1_ratio)
                model.fit(X_train_tensor, y_train_tensor, num_epochs=num_epochs, learning_rate=learning_rate)

                model.eval()
                with torch.no_grad():
                    val_predictions = model(X_val_tensor)
                    val_mse = nn.functional.mse_loss(val_predictions, y_val_tensor).item()
                    fold_mses.append(val_mse)

            avg_mse = np.mean(fold_mses)
            print(f"Alpha: {alpha}, L1_ratio: {l1_ratio}, Validation MSE: {avg_mse:.4f}")

            if avg_mse < best_mse:
                best_mse = avg_mse
                best_alpha = alpha
                best_l1_ratio = l1_ratio
                best_model = model.state_dict()  

    return best_alpha, best_l1_ratio, best_mse, best_model

X = data.drop(columns=['strength'])
y = data['strength']
scaler = StandardScaler()
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X)
X_scaled = scaler.fit_transform(X_poly)
X_np = X_scaled
y_np = y.to_numpy()
alphas = [0.1, 0.5]
l1_ratios = [0.1, 0.5, 0.9]  
best_alpha, best_l1_ratio, best_mse, best_model = cross_validate_elasticnet(X_np, y_np, alphas, l1_ratios, num_epochs=1000)

print(f"\nBest Alpha: {best_alpha}, Best L1 Ratio: {best_l1_ratio}, Best Cross-Validated MSE: {best_mse:.4f}")

model = ElasticNet(input_size=X_np.shape[1], alpha=best_alpha, l1_ratio=best_l1_ratio)
model.load_state_dict(best_model)
with torch.no_grad():
    coefficients = model.get_coefficients().cpu().numpy().flatten()
non_zero_weights = np.sum(np.abs(coefficients) > 1e-2)  

print(f"Ideal Model Size (number of variables with non-zero weights): {non_zero_weights}")
print(f"Coefficients: {coefficients}")
    </code></pre>

    <h3>Results</h3>
    <ul>
        <li><strong>Alpha: 0.1, L1_ratio: 0.1, Validation MSE:</strong> 64.8521</li>
        <li><strong>Alpha: 0.1, L1_ratio: 0.5, Validation MSE:</strong> 65.0555</li>
        <li><strong>Alpha: 0.1, L1_ratio: 0.9, Validation MSE:</strong> 65.3758</li>
        <li><strong>Alpha: 0.5, L1_ratio: 0.1, Validation MSE:</strong> 65.9953</li>
        <li><strong>Alpha: 0.5, L1_ratio: 0.5, Validation MSE:</strong> 67.9087</li>
        <li><strong>Alpha: 0.5, L1_ratio: 0.9, Validation MSE:</strong> 70.1001</li>
        <li><strong>Best Alpha:</strong> 0.1</li>
        <li><strong>Best L1 Ratio:</strong> 0.1</li>
        <li><strong>Best Cross-Validated MSE:</strong> 64.8521</li>
        <li><strong>Ideal Model Size (number of variables with non-zero weights):</strong> 43</li>
        <li><strong>Full Coefficients:</strong></li>
    </ul>

    <pre><code>
[ 2.37313886e+00  9.06353286e-01  9.33716037e-02 -1.20788273e+00
  5.03925146e-01  7.00941681e-03 -9.11565540e-02  2.88037989e+00
  1.13573815e+00  1.10831622e+00  2.11357943e+00  1.13894912e+00
 -3.97449215e-01  3.15663159e+00  1.92017783e+00  1.30657547e+00
 -1.30724099e+00  6.39884014e-01  1.36933651e+00  1.07986987e+00
  4.43364464e-01  2.00834705e+00  2.24173977e+00 -1.51885636e+00
 -5.93939059e-02 -1.55001631e+00  2.08916363e-01  1.05986730e+00
  2.13486535e+00 -7.86525131e-01  1.16160541e+00 -2.24508636e+00
 -8.90361722e-01  1.61021098e+00 -4.13934928e+00  1.45481993e+00
  7.06579790e-01  2.50470440e+00  1.68895519e-02  1.13281014e-01
  3.09951953e+00 -1.12286991e+00  4.48170725e+00 -9.16478855e+00]
    </code></pre>
</section>

<section>
    <h2>SqrtLasso Cross-Validation on Concrete Dataset</h2>

    <pre><code class="language-python">
def cross_validate_sqrt_lasso(model_class, X, y, alphas, num_folds=5, num_epochs=1000, learning_rate=0.01):
    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)
    best_alpha = None
    best_mse = float('inf')
    best_model = None
    all_fold_mses = []

    for alpha in alphas:
        fold_mses = []
        for train_index, val_index in kf.split(X):
            X_train, X_val = X[train_index], X[val_index]
            y_train, y_val = y[train_index], y[val_index]

            X_train_tensor = torch.tensor(X_train, dtype=torch.double)
            y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.double)
            X_val_tensor = torch.tensor(X_val, dtype=torch.double)
            y_val_tensor = torch.tensor(y_val.reshape(-1, 1), dtype=torch.double)

            if model_class == sqrtLasso:
                model = model_class(input_size=X_train.shape[1], alpha=alpha)
                model.fit(X_train_tensor, y_train_tensor, num_epochs=num_epochs, learning_rate=learning_rate)
            else:
                raise ValueError("Unknown model class")

            model.eval()
            with torch.no_grad():
                val_predictions = model(X_val_tensor)
                val_mse = nn.functional.mse_loss(val_predictions, y_val_tensor).item()
                fold_mses.append(val_mse)

        avg_mse = np.mean(fold_mses)
        all_fold_mses.append(avg_mse)
        print(f"Alpha: {alpha}, Validation MSE: {avg_mse:.4f}")

        if avg_mse < best_mse:
            best_mse = avg_mse
            best_alpha = alpha
            best_model = model.state_dict()  

    return best_alpha, best_mse, all_fold_mses, best_model


X = data.drop(columns=['strength'])
y = data['strength']
scaler = MinMaxScaler()
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X)
X_scaled = scaler.fit_transform(X_poly)
X_np = X_scaled
y_np = y.to_numpy()
alphas = [0.1, 0.5]
best_alpha, best_mse, all_fold_mses, best_model = cross_validate_sqrt_lasso(sqrtLasso, X_np, y_np, alphas, num_epochs=1000)

print(f"\nBest Alpha: {best_alpha}, Best Cross-Validated MSE: {best_mse:.4f}")

model = sqrtLasso(input_size=X_np.shape[1], alpha=best_alpha)
model.load_state_dict(best_model)
with torch.no_grad():
    coefficients = model.get_coefficients().cpu().numpy().flatten()
non_zero_weights = np.sum(np.abs(coefficients) > 1)  

print(f"Ideal Model Size (number of variables with non-zero weights): {non_zero_weights}")
print(f"Cross-Validated MSEs across all folds: {all_fold_mses}")
print(f"Coefficients: {coefficients}")
    </code></pre>

    <h3>Results</h3>
    <ul>
        <li><strong>Alpha: 0.1, Validation MSE:</strong> 129.1919</li>
        <li><strong>Alpha: 0.5, Validation MSE:</strong> 132.0758</li>
        <li><strong>Best Alpha:</strong> 0.1</li>
        <li><strong>Best Cross-Validated MSE:</strong> 129.1919</li>
        <li><strong>Ideal Model Size (number of variables with non-zero weights):</strong> 36</li>
        <li><strong>Full Coefficients:</strong></li>
    </ul>

    <pre><code>
[ 5.68596423  3.47554761  0.90990143  1.80437916  4.29606457  2.79076772
  1.85914775  5.31771261  6.26410827  5.50153176  3.29584782  5.60432414
  5.3358012   5.53639732  5.59213085  6.14206708  2.69628793  0.45726294
  2.92397486  5.71898156  3.38169535  3.344988    5.41906863 -0.13592886
  0.3783961   0.16418269  0.64324518  0.66590532  5.94620951  1.52022699
  4.06091041  1.56692651  0.81555875  4.87070289  3.54236243  4.28697075
  4.36839147  7.35384986  2.73594379  1.95714512  5.61355563  1.67396253
  5.49115194  1.67004204]
    </code></pre>
</section>

<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-python.min.js"></script>

</body>
</html>
