<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>My GitHub Page</title>
</head>
<body>
    <h1>Welcome to My GitHub Page</h1>
    <p>This is my personal website hosted on GitHub Pages!</p>

    <h2>Automated Cross-Validation for LWR and Random Forest</h2>

    <p>My code displays a class that implements a Locally Weighted Regression (LWR), a regression technique that emphasizes local data points when making predictions. It also offers the option to compare this method with Random Forest by switching the model type.</p>

    <p>The cross_validate function in the class incorporates all the other functions from the class for optimal automation. It brings together the fit, predict, mse, and r2_score functions to automate the K-fold cross-validation for Locally Weighted Regression (LWR) and Random Forest.</p>

    <h3>Kernel Functions</h3>
    <p>Before we get into the functions within the class, there are four kernel functions outside of the class that help create the weights for LWR:</p>
    <ul>
        <li>Gaussian</li>
        <li>Tricubic</li>
        <li>Epanechnikov</li>
        <li>Quartic</li>
    </ul>
    <p>The different kernel functions allow the user to test and choose the most accurate one.</p>


    <h3>PatricksModel Class Constructor (<code>__init__</code>)</h3>
    <p>The constructor accepts several parameters:</p>
    <ul>
        <li><b>model type</b>: Either 'lwr' for Locally Weighted Regression or 'rf' for Random Forest.</li>
        <li><b>kernel type</b>: Used for LWR, can be 'tricubic', 'gaussian', etc.</li>
        <li><b>neighborhood fraction (f)</b>: Fraction of the data used to determine nearby points in LWR.</li>
        <li><b>number of iterations (iter)</b>: Number of iterations for the LWR fitting process.</li>
        <li><b>include intercept</b>: Whether to include an intercept in the regression (True or False).</li>
    </ul>
    <p><b>Random Forest Parameters</b>: If the model type is 'rf', the constructor initializes a Random Forest with specific parameters:</p>
    <ul>
        <li><b>n_estimators</b>: The number of trees in the forest.</li>
        <li><b>max_depth</b>: The maximum depth of the tree.</li>
        <li><b>random_state</b>: Controls randomness for reproducibility.</li>
    </ul>
    <p>If no parameters are provided, default values are used for Random Forest.</p>

    <h3>Kernel Selection (<code>_get_kernel</code>)</h3>
    <p>Based on the kernel type specified during initialization, this method returns the appropriate kernel function. The available kernel options include:</p>
    <ul>
        <li><b>Gaussian</b></li>
        <li><b>Tricubic</b></li>
        <li><b>Epanechnikov</b></li>
        <li><b>Quartic</b></li>
    </ul>
    <p>If an unknown kernel type is passed during initialization, the method raises an error, ensuring the user selects a valid kernel function.</p>

    <h3>Weight Calculation (<code>_weight_calculation</code>)</h3>
    <p>This function calculates the weights for each training point relative to the new data point. It computes the Euclidean distance between each training point and the new point, applies the selected kernel function, and scales the distances to generate weights. The number of neighbors considered is determined by the fraction (<code>f</code>) of total training samples.</p>
    
    <h3>Prediction (<code>predict</code>)</h3>
    <p>In LWR, predictions are made by scaling the new input data, computing weights using the training data, and solving for the regression coefficients via weighted least squares. The function iterates through the training data to adjust the weights and recalculates residuals to improve predictions. L2 regularization is used for stability.</p>
    <p>For Random Forest, the <code>predict</code> function of the Random Forest model is used to generate predictions.</p>
    
    <h3>Model Evaluation (<code>mse</code>, <code>r2_score</code>)</h3>
    <p>Two functions are provided to evaluate the performance of the model:</p>
    <ul>
        <li><b><code>mse</code></b>: Calculates the Mean Squared Error (MSE) between true and predicted values.</li>
        <li><b><code>r2_score</code></b>: Computes the R² score, which measures how well the model explains the variance in the data.</li>
    </ul>
    
    <h3>Cross-Validate Function (<code>cross_validate</code>)</h3>
    <p>All of these functions cumulate into the <code>cross_validate</code> function. This function automates the evaluation of either Locally Weighted Regression (LWR) or Random Forest by incorporating several key functions in the class, allowing for efficient model training, prediction, and performance assessment.</p>
    
    <h4>Key Steps:</h4>
    <ul>
        <li><b>K-Fold Cross-Validation:</b> It splits the dataset into <code>n_splits</code> (default 10) folds, using each fold as a test set once, while training on the remaining data.</li>
        <li><b>Model Fitting:</b> Calls <code>fit</code> to train either the LWR or Random Forest model on each fold.</li>
        <li><b>Prediction:</b> Uses <code>predict</code> to generate predictions for the test data.</li>
        <li><b>Performance Metrics:</b> Automatically calculates Mean Squared Error (MSE) and R² score for each fold using <code>mse</code> and <code>r2_score</code>.</li>
        <li><b>Averaging:</b> The function averages the MSE and R² scores across all folds and prints the results.</li>
    </ul>
    
    <h4>Key Benefit:</h4>
    <p>Without <code>cross_validate</code>, you’d need to manually split the data, fit the model, predict, and calculate metrics for each fold. This function automates the entire process, making it fast and convenient to evaluate both models on the same dataset.</p>


    


</body>
</html>
